---
Fecha de creaci贸n: <% tp.date.now("YYYY-MM-DD HH:mm") %>
Fecha de Modificaci贸n: <% tp.date.now("YYYY-MM-DD HH:mm") %>
tags: 
Tema: Mecanismo de Atenci贸n
---

##  Idea/Concepto 
Mecanismo en Transformers que calcula relaciones entre tokens simult谩neamente mediante proyecciones Query-Key-Value. Calcula compatibilidades con producto punto escalado, normaliza con softmax y pondera Values. Multi-Head Attention ejecuta esto en paralelo, permitiendo procesamiento completo vs. secuencial de RNNs.

##  Puntos Claves
- Proyecciones paralelas: Q, K, V para cada token
- Producto punto escalado: compatibilidad Query-Key / dk
- Softmax para normalizaci贸n de pesos de atenci贸n
- Multi-Head: m煤ltiples subespacios de representaci贸n
- Procesamiento paralelo completo vs. RNNs secuenciales
- Requiere codificaci贸n posicional expl铆cita

##  Connections
- [[Large Language Models]]
- [[Ventana Contextual]]
- [[Embeddings]]
- [[Redes Neuronales]]

##  Personal Insight
La atenci贸n permite que cada token "mire" a todos los dem谩s simult谩neamente, creando representaciones verdaderamente contextualizadas en tiempo constante.

## Ь Recursos
-